
@MISC{Damian2022-mk,
  title        = "Basic Inference Engine: Streamlined Model Deployment",
  author       = "Damian, Andrei Ionut",
  abstract     = "The Basic Inference Server library encapsulates a streamlined
                  approach towards deploying machine learning models
                  efficiently. With the objective of modularity and ease of
                  integration, this library is fabricated to operate both as a
                  standalone Python package and as a submodule within broader
                  systems. Its architecture is designed to meld seamlessly with
                  contemporary CI/CD pipelines, thereby promoting a
                  frictionless transition from model development to deployment.",
  year         =  2022,
  howpublished = "\url{https://github.com/andreiionutdamian/basic_inference_server}"
}


@INPROCEEDINGS{Korotaeva2018-gb,
  title       = "Botanicum: a telegram bot for tree classification",
  booktitle   = "2018 22nd Conference of Open Innovations Association ({FRUCT})",
  author      = "Korotaeva, Daria and Khlopotov, Maksim and Makarenko,
                 Anastasiia and Chikshova, Ekaterina and Startseva, Natalia and
                 Chemysheva, Anastasiia",
  pages       = "88--93",
  institution = "IEEE",
  year        =  2018
}

@MISC{Toledo_undated-kj,
  title        = "Python-telegram-bot Documentation",
  author       = "Toledo, L",
  howpublished = "\url{https://media.readthedocs.org/pdf/python-telegram-bot/latest/python-telegram-bot.pdf}",
  note         = "Accessed: 2023-10-22"
}

@BOOK{Brazil2018-tv,
  title     = "Prometheus: Up \& Running: Infrastructure and Application
               Performance Monitoring",
  author    = "Brazil, Brian",
  abstract  = "Get up to speed with Prometheus, the metrics-based monitoring
               system used by tens of thousands of organizations in production.
               This practical guide provides application developers, sysadmins,
               and DevOps practitioners with a hands-on introduction to the
               most important aspects of Prometheus, including dashboarding and
               alerting, direct code instrumentation, and metric collection
               from third-party systems with exporters.This open source system
               has gained popularity over the past few years for good reason.
               With its simple yet powerful data model and query language,
               Prometheus does one thing, and it does it well. Author and
               Prometheus developer Brian Brazil guides you through Prometheus
               setup, the Node exporter, and the Alertmanager, then
               demonstrates how to use them for application and infrastructure
               monitoring.Know where and how much to apply instrumentation to
               your application codeIdentify metrics with labels using unique
               key-value pairsGet an introduction to Grafana, a popular tool
               for building dashboardsLearn how to use the Node Exporter to
               monitor your infrastructureUse service discovery to provide
               different views of your machines and servicesUse Prometheus with
               Kubernetes and examine exporters you can use with
               containersConvert data from other monitoring systems into the
               Prometheus format",
  publisher = "``O'Reilly Media, Inc.''",
  month     =  jul,
  year      =  2018,
  language  = "en"
}

@INCOLLECTION{Chakraborty2021-hv,
  title     = "Grafana",
  booktitle = "Monitoring {Cloud-Native} Applications: Lead Agile Operations
               Confidently Using Open Source Software",
  author    = "Chakraborty, Mainak and Kundan, Ajit Pratap",
  editor    = "Chakraborty, Mainak and Kundan, Ajit Pratap",
  abstract  = "Grafana is a popular open source time-series data query,
               visualization, and alerting tool which was developed by Torkel
               {\"O}degaard in 2014. It has a data source model which is highly
               pluggable and supports multiple time-series--based data sources
               like Prometheus, InfluxDB, and OpenTSDB as well as SQL databases
               like MySQL and Postgres. Independent of where the data is
               stored, it allows you to query the data using query editor,
               visualize it using dashboards, and alert on it using the
               alerting function.",
  publisher = "Apress",
  pages     = "187--240",
  year      =  2021,
  address   = "Berkeley, CA"
}

@INCOLLECTION{McCollam2022-xd,
  title     = "Grafana Cloud",
  booktitle = "Getting Started with Grafana: {Real-Time} Dashboards for {IT}
               and Business Operations",
  author    = "McCollam, Ronald",
  editor    = "McCollam, Ronald",
  abstract  = "As a widely used open source tool, Grafana can be deployed in a
               nearly limitless number of ways and at scales ranging from a
               single instance on a pocket-sized Raspberry Pi up to highly
               available multiregion deployments with hundreds of nodes.
               Figuring out the best way to deploy it for your own environment
               can seem a bit daunting. The fastest way to get started is to
               create a free account on Grafana Cloud. We'll walk through that
               process and start to learn the Grafana interface in Chapter 1.",
  publisher = "Apress",
  pages     = "3--17",
  year      =  2022,
  address   = "Berkeley, CA"
}

@MISC{Radford_undated-yo,
  title        = "Language Models are Unsupervised Multitask Learners",
  author       = "Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan,
                  David and Amodei, Dario and Sutskever, Ilya",
  howpublished = "\url{https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf}",
  note         = "Accessed: 2023-10-21"
}

@ARTICLE{Touvron2023-ow,
  title         = "Llama 2: Open Foundation and {Fine-Tuned} Chat Models",
  author        = "Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert,
                   Peter and Almahairi, Amjad and Babaei, Yasmine and
                   Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal
                   and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and
                   Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem
                   and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu,
                   Wenyin and Fuller, Brian and Gao, Cynthia and Goswami,
                   Vedanuj and Goyal, Naman and Hartshorn, Anthony and
                   Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas,
                   Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann,
                   Isabel and Korenev, Artem and Koura, Punit Singh and
                   Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and
                   Liskovich, Diana and Lu, Yinghai and Mao, Yuning and
                   Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and
                   Molybog, Igor and Nie, Yixin and Poulton, Andrew and
                   Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and
                   Schelten, Alan and Silva, Ruan and Smith, Eric Michael and
                   Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh
                   and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang
                   and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang,
                   Yuchen and Fan, Angela and Kambadur, Melanie and Narang,
                   Sharan and Rodriguez, Aurelien and Stojnic, Robert and
                   Edunov, Sergey and Scialom, Thomas",
  abstract      = "In this work, we develop and release Llama 2, a collection
                   of pretrained and fine-tuned large language models (LLMs)
                   ranging in scale from 7 billion to 70 billion parameters.
                   Our fine-tuned LLMs, called Llama 2-Chat, are optimized for
                   dialogue use cases. Our models outperform open-source chat
                   models on most benchmarks we tested, and based on our human
                   evaluations for helpfulness and safety, may be a suitable
                   substitute for closed-source models. We provide a detailed
                   description of our approach to fine-tuning and safety
                   improvements of Llama 2-Chat in order to enable the
                   community to build on our work and contribute to the
                   responsible development of LLMs.",
  month         =  jul,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2307.09288"
}

@ARTICLE{Franchini2020-fu,
  title    = "Shifting the Paradigm: The {Dress-COV} Telegram Bot as a Tool for
              Participatory Medicine",
  author   = "Franchini, Michela and Pieroni, Stefania and Martini, Nicola and
              Ripoli, Andrea and Chiappino, Dante and Denoth, Francesca and
              Liebman, Michael Norman and Molinaro, Sabrina and Della Latta,
              Daniele",
  abstract = "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)
              pandemic management is limited by great uncertainty, for both
              health systems and citizens. Facing this information gap requires
              a paradigm shift from traditional approaches to healthcare to the
              participatory model of improving health. This work describes the
              design and function of the Doing Risk sElf-assessment and Social
              health Support for COVID (Dress-COV) system. It aims to establish
              a lasting link between the user and the tool; thus, enabling
              modeling of the data to assess individual risk of infection, or
              developing complications, to improve the individual's
              self-empowerment. The system uses bot technology of the Telegram
              application. The risk assessment includes the collection of user
              responses and the modeling of data by machine learning models,
              with increasing appropriateness based on the number of users who
              join the system. The main results reflect: (a) the individual's
              compliance with the tool; (b) the security and versatility of the
              architecture; (c) support and promotion of self-management of
              behavior to accommodate surveillance system delays; (d) the
              potential to support territorial health providers, e.g., the
              daily efforts of general practitioners (during this pandemic, as
              well as in their routine practices). These results are unique to
              Dress-COV and distinguish our system from classical surveillance
              applications.",
  journal  = "Int. J. Environ. Res. Public Health",
  volume   =  17,
  number   =  23,
  month    =  nov,
  year     =  2020,
  keywords = "COVID-19; SARS-CoV-2; co-morbidity profile; participatory
              medicine; telegram bot",
  language = "en"
}

@BOOK{Modrzyk2018-ao,
  title     = "Building Telegram Bots: Develop Bots in 12 Programming Languages
               using the Telegram Bot {API}",
  author    = "Modrzyk, Nicolas",
  abstract  = "Learn about bot programming, using all the latest and greatest
               programming languages, including Python, Go, and Clojure, so you
               can feel at ease writing your Telegram bot in a way that suits
               you.This book shows how you can use bots for just about
               everything: they connect, they respond, they enhance your job
               search chances, they do technical research for you, they remind
               you about your last train, they tell the difference between a
               horse and a zebra, they can tell jokes, and they can cheer you
               up in the middle of the night. Bots used to be hard to set up
               and enhance, but with the help of Building Telegram Bots you'll
               see how the Telegram platform is now making bot creation easier
               than ever. You will begin by writing a simple bot at the start
               and then gradually build upon it. The simple yet effective
               Telegram Bot API makes it very easy to develop bots in a number
               of programming languages. Languages featured in the book include
               Node.js, Java, Rust, and Elixir. This book encourages you to not
               only learn the basic process of creating a bot but also lets you
               spend time exploring its possibilities. By the end of the book
               you will be able create your own Telegram Bot with the
               programming language of your choice. What You Will LearnCarry
               out simple bot design and deployment in various programming
               languages including Ruby, D, Crystal, Nim, and C++Create
               engaging bot interactions with your usersAdd payments and media
               capabilities to your botsMaster programming language
               abstractionWho This Book Is ForEngineers who want to get things
               done. People who are curious. Programming beginners. Advanced
               engineers with little time to do research.",
  publisher = "Apress",
  month     =  dec,
  year      =  2018,
  language  = "en"
}

@BOOK{Nadareishvili2016-xh,
  title     = "Microservice architecture: aligning principles, practices, and
               culture",
  author    = "Nadareishvili, Irakli and Mitra, Ronnie and McLarty, Matt and
               Amundsen, Mike",
  publisher = "`` O'Reilly Media, Inc.''",
  year      =  2016
}

@BOOK{Beyer2016-ay,
  title     = "Site reliability engineering: How Google runs production systems",
  author    = "Beyer, Betsy and Jones, Chris and Petoff, Jennifer and Murphy,
               Niall Richard",
  publisher = "`` O'Reilly Media, Inc.''",
  year      =  2016
}

@BOOK{Allen2017-fb,
  title     = "Reactive design patterns",
  author    = "Allen, Jamie",
  publisher = "Simon and Schuster",
  year      =  2017
}

@BOOK{Grinberg2018-zn,
  title     = "Flask web development: developing web applications with python",
  author    = "Grinberg, Miguel",
  publisher = "`` O'Reilly Media, Inc.''",
  year      =  2018
}

@ARTICLE{Schwartz2019-kt,
  title   = "Green {AI}",
  author  = "Schwartz, Roy and Dodge, Jesse and Smith, Noah A and Etzioni, Oren",
  journal = "arXiv preprint arXiv:1907. 10597",
  year    =  2019
}

@ARTICLE{Strubell2019-ou,
  title   = "Energy and policy considerations for deep learning in {NLP}",
  author  = "Strubell, Emma and Ganesh, Ananya and McCallum, Andrew",
  journal = "arXiv preprint arXiv:1906. 02243",
  year    =  2019
}

@ARTICLE{Luccioni2022-nu,
  title   = "Estimating the carbon footprint of bloom, a 176b parameter
             language model",
  author  = "Luccioni, Alexandra Sasha and Viguier, Sylvain and Ligozat,
             Anne-Laure",
  journal = "arXiv preprint arXiv:2211. 02001",
  year    =  2022
}

@ARTICLE{Gupta2020-or,
  title   = "{MLOps}: Continuous delivery and automation pipelines in machine
             learning",
  author  = "Gupta, Devops and {Others}",
  journal = "arXiv preprint arXiv:2010. 02500",
  year    =  2020
}

@BOOK{Treveil2020-ku,
  title     = "Introducing {MLOps}",
  author    = "Treveil, Mark and Omont, Nicolas and Stenac, Cl{\'e}ment and
               Lefevre, Kenji and Phan, Du and Zentici, Joachim and
               Lavoillotte, Adrien and Miyazaki, Makoto and Heidmann, Lynn",
  publisher = "O'Reilly Media",
  year      =  2020
}

@ARTICLE{Kreuzberger2023-pq,
  title     = "Machine learning operations (mlops): Overview, definition, and
               architecture",
  author    = "Kreuzberger, Dominik and K{\"u}hl, Niklas and Hirschl, Sebastian",
  journal   = "IEEE Access",
  publisher = "IEEE",
  year      =  2023
}

@INPROCEEDINGS{Brown2020-ca,
  title     = "Language Models are {Few-Shot} Learners",
  booktitle = "Advances in Neural Information Processing Systems",
  author    = "Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah,
               Melanie and Kaplan, Jared D and Dhariwal, Prafulla and
               Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and
               Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and
               Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh,
               Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens
               and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin,
               Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and
               Berner, Christopher and McCandlish, Sam and Radford, Alec and
               Sutskever, Ilya and Amodei, Dario",
  editor    = "Larochelle, H and Ranzato, M and Hadsell, R and Balcan, M F and
               Lin, H",
  publisher = "Curran Associates, Inc.",
  volume    =  33,
  pages     = "1877--1901",
  year      =  2020
}

@ARTICLE{Milik2023-ku,
  title   = "{AiXpand} {AI} {OS--Decentralized} ubiquitous computing {MLOps}
             execution engine",
  author  = "Milik, Beatrice and Saraev, Stefan and Bleotiu, Cristian and
             Lupaescu, Radu and Hobeanu, Bogdan and Damian, Andrei Ionut",
  journal = "arXiv preprint arXiv:2306. 08708",
  year    =  2023
}

@ARTICLE{Ciobanu2021-qr,
  title   = "{SOLIS--The} {MLOps} journey from data acquisition to actionable
             insights",
  author  = "Ciobanu, Razvan and Purdila, Alexandru and Piciu, Laurentiu and
             Damian, Andrei",
  journal = "arXiv preprint arXiv:2112. 11925",
  year    =  2021
}
